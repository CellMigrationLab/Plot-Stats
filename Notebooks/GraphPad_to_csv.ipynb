{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **GraphPad Prism `.pzfx` File to `.csv` Converter**\n",
        "\n",
        "## **Description**\n",
        "This notebook is designed to parse and convert GraphPad Prism `.pzfx` files into multiple `.csv` files, each representing a table in the original file. After conversion, all `.csv` files are zipped into a single `.zip` archive, which can be manually downloaded from the Colab file browser.\n",
        "\n",
        "## **Features**\n",
        "- Parses `.pzfx` files to extract tables as `pandas` DataFrames.\n",
        "- Converts each table to a `.csv` file.\n",
        "- Combines all generated `.csv` files into a `.zip` archive for convenience.\n",
        "- Allows manual download of the `.zip` file via the Colab file browser.\n",
        "\n",
        "## **How to Use**\n",
        "1. **Upload `.pzfx` File**: Run the notebook and upload your `.pzfx` file when prompted.\n",
        "2. **Processing**: The notebook will parse the file and extract all tables.\n",
        "3. **Download**: After processing, the resulting `.zip` file will be available in the **Files** pane (on the left side of Colab). Manually download it by:\n",
        "   - Clicking the **Files** icon on the left sidebar.\n",
        "   - Navigating to `converted_tables.zip`.\n",
        "   - Right-clicking the file and selecting **Download**.\n",
        "\n",
        "## **Output**\n",
        "- A `.zip` archive named `converted_tables.zip` containing all the `.csv` files.\n",
        "\n",
        "## **Note**\n",
        "Ensure your `.pzfx` files are valid and compatible with GraphPad Prism XML version 5.00 to avoid parsing errors.\n",
        "\n",
        "## **Example Workflow**\n",
        "1. Run the first cell to upload your `.pzfx` file.\n",
        "2. Let the notebook process the file and generate the `.csv` files.\n",
        "3. Locate `converted_tables.zip` in the Colab **Files** pane and download it manually.\n",
        "\n",
        "## **Troubleshooting**\n",
        "- If a table fails to parse, ensure the `.pzfx` file format matches the expected XML structure.\n",
        "- Check for missing or invalid data in your `.pzfx` file if the output seems incomplete.\n",
        "- If the download doesn't start automatically, use the manual download instructions above.\n"
      ],
      "metadata": {
        "id": "aMQXf6rN-MYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run to install\n",
        "\n",
        "\n",
        "!pip install -q pandas openpyxl\n",
        "\n",
        "# Step 2: Define the Prism File Parser\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "from itertools import count, chain, cycle\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class PrismFileLoadError(Exception):\n",
        "    pass\n",
        "\n",
        "def _get_all_text(element):\n",
        "    s = ''\n",
        "    for c in element.iter():\n",
        "        if c.text is not None:\n",
        "            s += c.text\n",
        "    return s\n",
        "\n",
        "def _subcolumn_to_numpy(subcolumn, ns):\n",
        "    try:\n",
        "        data = []\n",
        "        for d in subcolumn.findall('d', ns):\n",
        "            if not (('Excluded' in d.attrib) and (d.attrib['Excluded'] == '1')):\n",
        "                if _get_all_text(d) == '':\n",
        "                    data.append(None)\n",
        "                else:\n",
        "                    data.append(float(_get_all_text(d)))\n",
        "            else:\n",
        "                data.append(np.nan)\n",
        "    except Exception as a:\n",
        "        print(f\"Couldn't Read a column in the file because: {a}\")\n",
        "        data = None\n",
        "\n",
        "    return np.array(data)\n",
        "\n",
        "def _parse_xy_table(table, ns):\n",
        "    xformat = table.attrib['XFormat']\n",
        "    try:\n",
        "        yformat = table.attrib['YFormat']\n",
        "    except KeyError:\n",
        "        yformat = None\n",
        "    evformat = table.attrib['EVFormat']\n",
        "\n",
        "    xscounter = count()\n",
        "    xsubcolumn_names = lambda: str(next(xscounter))\n",
        "    if yformat == 'SEN':\n",
        "        yslist = cycle(['Mean', 'SEM', 'N'])\n",
        "        ysubcolumn_names = lambda: next(yslist)\n",
        "    elif yformat == 'upper-lower-limits':\n",
        "        yslist = cycle(['Mean', 'Lower', 'Upper'])\n",
        "        ysubcolumn_names = lambda: next(yslist)\n",
        "    else:\n",
        "        yscounter = count()\n",
        "        ysubcolumn_names = lambda: str(next(yscounter))\n",
        "\n",
        "    index = None\n",
        "    for row_titles in table.findall('RowTitlesColumn', ns):\n",
        "        for subcolumn in row_titles.findall('Subcolumn', ns):\n",
        "            titles = []\n",
        "            for d in subcolumn.findall('d', ns):\n",
        "                titles.append(_get_all_text(d))\n",
        "            index = pd.Index(titles)\n",
        "\n",
        "    columns = {}\n",
        "    for xcolumn in chain(table.findall('XColumn', ns), table.findall('XAdvancedColumn', ns)):\n",
        "        xcolumn_name = _get_all_text(xcolumn.find('Title', ns))\n",
        "        for subcolumn in xcolumn.findall('Subcolumn', ns):\n",
        "            subcolumn_name = xcolumn_name + '_' + xsubcolumn_names()\n",
        "            columns[subcolumn_name] = _subcolumn_to_numpy(subcolumn, ns)\n",
        "    for ycolumn in chain(table.findall('YColumn', ns), table.findall('YAdvancedColumn', ns)):\n",
        "        ycolumn_name = _get_all_text(ycolumn.find('Title', ns))\n",
        "        for subcolumn in ycolumn.findall('Subcolumn', ns):\n",
        "            subcolumn_name = ycolumn_name + '_' + ysubcolumn_names()\n",
        "            columns[subcolumn_name] = _subcolumn_to_numpy(subcolumn, ns)\n",
        "\n",
        "    maxlength = max([v.shape[0] if v.shape != () else 0 for v in columns.values()])\n",
        "    for k, v in columns.items():\n",
        "        if v.shape != ():\n",
        "            if v.shape[0] < maxlength:\n",
        "                columns[k] = np.pad(v, (0, maxlength - v.shape[0]), mode='constant', constant_values=np.nan)\n",
        "        else:\n",
        "            columns[k] = np.pad(v, (0, maxlength - 0), mode='constant', constant_values=np.nan)\n",
        "\n",
        "    return pd.DataFrame(columns, index=index)\n",
        "\n",
        "def _parse_table_to_dataframe(table, ns):\n",
        "    tabletype = table.attrib['TableType']\n",
        "\n",
        "    if tabletype in {'XY', 'TwoWay', 'OneWay'}:\n",
        "        df = _parse_xy_table(table, ns)\n",
        "    else:\n",
        "        raise PrismFileLoadError(f'Cannot parse {tabletype} tables for now!')\n",
        "\n",
        "    return df\n",
        "\n",
        "def read_pzfx(filename):\n",
        "    \"\"\"Open and parse the Prism pzfx file given in `filename`.\"\"\"\n",
        "    tree = ET.parse(filename)\n",
        "    root = tree.getroot()\n",
        "    if root.tag == 'GraphPadPrismFile':\n",
        "        ns = None\n",
        "    elif root.tag == '{http://graphpad.com/prism/Prism.htm}GraphPadPrismFile':\n",
        "        ns = {'': 'http://graphpad.com/prism/Prism.htm'}\n",
        "    else:\n",
        "        raise PrismFileLoadError('Not a Prism file!')\n",
        "    if root.attrib['PrismXMLVersion'] != '5.00':\n",
        "        raise PrismFileLoadError('Can only load Prism files with XML version 5.00!')\n",
        "\n",
        "    tables = {_get_all_text(table.find('Title', ns)): _parse_table_to_dataframe(table, ns)\n",
        "              for table in root.findall('Table', ns)}\n",
        "\n",
        "    return tables\n"
      ],
      "metadata": {
        "id": "7oHzjQUDkmmH",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run to process\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import os\n",
        "from itertools import count, chain, cycle\n",
        "from IPython.display import FileLink  # Import FileLink to provide download links\n",
        "from google.colab import files\n",
        "from IPython.display import HTML\n",
        "\n",
        "# Upload your .pzfx file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Create a directory for the output CSVs\n",
        "output_dir = \"converted_csvs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Parse and save CSVs\n",
        "for filename in uploaded.keys():\n",
        "    # Parse the .pzfx file\n",
        "    tables = read_pzfx(filename)\n",
        "\n",
        "    # Save each table as a CSV file\n",
        "    for table_name, df in tables.items():\n",
        "        csv_name = os.path.join(output_dir, f\"{table_name}.csv\".replace('/', '_'))\n",
        "        df.to_csv(csv_name, index=False)\n",
        "        print(f\"Saved table '{table_name}' to '{csv_name}'\")\n",
        "\n",
        "#  Zip All CSV Files\n",
        "zip_filename = \"converted_tables.zip\"\n",
        "with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "    for root, dirs, files in os.walk(output_dir):\n",
        "        for file in files:\n",
        "            zipf.write(os.path.join(root, file), arcname=file)\n"
      ],
      "metadata": {
        "id": "NoS0_AFUo7QE",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}