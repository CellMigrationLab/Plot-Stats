{"cells":[{"cell_type":"markdown","metadata":{"id":"xF4zYMmXULP7"},"source":["# **Plot&Stats - wide to tidy**\n","---\n","\n","<font size = 4>Colab Notebook for Plotting data\n","\n","\n","<font size = 4>Notebook created by [Guillaume Jacquemet](https://cellmig.org/)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"aR2U8v9YoJcW"},"source":["# **Part 0. Before getting started**\n","---\n","\n","Wide and tidy formats represent two principal ways of structuring tabular data:\n","\n","- **Wide Format**:\n","  - Each row represents a subject or item.\n","  - Observations spread across multiple columns.\n","  - Suitable for data entry or presentation.\n","  - Example with biological repeats:\n","    ```\n","    | Subject | Cond1_Repeat1 | Cond1_Repeat2 | Cond2_Repeat1 | Cond2_Repeat2 |\n","    |---------|---------------|---------------|---------------|---------------|\n","    | 1       | ValueA        | ValueB        | ValueC        | ValueD        |\n","    ```\n","\n","- **Tidy Format**:\n","  - Each column is a variable, each row an observation.\n","  - Suited for statistical analysis and plotting.\n","  - Each row represents a unique combination of variables.\n","  - Example with biological repeats:\n","    ```\n","    | Subject | Condition | Repeat | Value  |\n","    |---------|-----------|--------|--------|\n","    | 1       | Cond1     | 1      | ValueA |\n","    | 1       | Cond1     | 2      | ValueB |\n","    | 1       | Cond2     | 1      | ValueC |\n","    | 1       | Cond2     | 2      | ValueD |\n","    ```\n","\n","Wide format is more readable for direct comparisons across a subject's measurements, while tidy format is optimized for analysis, making data transformations, summarizations, and visualizations more straightforward.\n","\n","\n","\n","\n","<font size = 5>**Important notes**\n","\n","---\n","\n","## Data Preparation and Loading Instructions\n","\n","This notebook is designed to transform wide-format data into a tidy format for further analysis. To ensure smooth operation, please follow the guidelines below regarding the data format and how to use the notebook.\n","\n","### File Format\n","- **CSV**: Data should be in CSV (Comma-Separated Values) format, easily generated from spreadsheet applications (e.g., Excel, Google Sheets) or statistical software (e.g., R, Python).\n","- **Copy and Paste**: Data can be directly copied and pasted from a spreedsheet software.\n","\n","### Expected Data Format\n","\n","Your dataset should be structured in a wide format, where:\n","\n","- **Columns** represent different conditions and their repeats. The naming convention should follow the pattern `ConditionName_R#`, where `ConditionName` is a unique identifier for the condition, and `R#` indicates the repeat number (e.g., `R1`, `R2` for repeats 1 and 2, respectively).\n","- **Rows** represent individual subjects, samples, or experimental units with measurements under each condition and repeat.\n","\n","### Example Dataset\n","\n","Below is an example of how your data might look when correctly formatted. Note that missing values are allowed:\n","\n","| Condition1_R1 | Condition1_R2 | Condition2_R1 | Condition2_R2 | Condition3_R1 | Condition3_R2 |\n","|---------------|---------------|---------------|---------------|---------------|---------------|\n","| 0.5           | 0.6           | 0.7           | 0.8           | 0.9           | 0.95          |\n","| 0.55          |               | 0.75          |               | 1.0           | 1.05          |\n","|               | 0.65          |               | 0.85          | 1.1           | 1.15          |\n","| 0.56          | 0.66          | 0.76          |               | 1.2           |               |\n","| 0.57          | 0.67          | 0.77          | 0.87          | 1.25          | 1.3           |\n","\n","### How to Use This Notebook\n","\n","1. **Load Your Data**: Use the widget provided at the beginning of the notebook to either enter the path to your CSV file or paste your data directly into the text area provided.\n","   - If entering a file path, ensure the path is correct and accessible by the notebook.\n","   - If pasting data, ensure it is tab-separated as shown in the example above.\n","\n","2. **Specify the Results Folder**: Enter the path where you'd like the transformed tidy dataset and any analysis results to be saved. If the specified folder does not exist, it will be created automatically.\n","\n","3. **Execute the Transformation**: Run the notebook cells in order. The notebook will automatically transform your wide-format data into a tidy format, handle missing values appropriately, and save the tidy dataset as `tidy.csv` in the specified results folder.\n","\n","4. **Review and Analyze**: After transformation, you can proceed with further data analysis within the same notebook or use the tidy dataset in other analytical tools or notebooks.\n","\n","### Notes\n","\n","- The notebook is designed to handle datasets with varying numbers of data points across conditions and repeats by appropriately managing missing values.\n","- Ensure that any specific data processing or cleaning requirements are addressed either before loading the data into this notebook or within the notebook as part of the transformation process.\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"JrkfFr7mgZmA"},"outputs":[],"source":["# @title #MIT License\n","\n","print(\"\"\"\n","**MIT License**\n","\n","Copyright (c) 2023 Guillaume Jacquemet\n","\n","Permission is hereby granted, free of charge, to any person obtaining a copy\n","of this software and associated documentation files (the \"Software\"), to deal\n","in the Software without restriction, including without limitation the rights\n","to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n","copies of the Software, and to permit persons to whom the Software is\n","furnished to do so, subject to the following conditions:\n","\n","The above copyright notice and this permission notice shall be included in all\n","copies or substantial portions of the Software.\n","\n","THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n","IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n","FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n","AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n","LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n","OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n","SOFTWARE.\"\"\")"]},{"cell_type":"markdown","metadata":{"id":"Y4-Ft-yNRVCc"},"source":["--------------------------------------------------------\n","# **Part 1. Prepare the session and load your data**\n","--------------------------------------------------------\n"]},{"cell_type":"markdown","metadata":{"id":"9h0prdayn0qG"},"source":["## **1.1. Install key dependencies**\n","---\n","<font size = 4>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rAP0ahCzn1V6","cellView":"form"},"outputs":[],"source":["#@markdown ##Play to load the dependancies\n","\n","import ipywidgets as widgets\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from matplotlib.backends.backend_pdf import PdfPages\n","import numpy as np\n","import itertools\n","from matplotlib.gridspec import GridSpec\n","import requests\n","\n","!pip freeze > requirements.txt\n","\n","\n","# Current version of the notebook the user is running\n","current_version = \"0.1\"\n","Notebook_name = 'wide2tidy'\n","\n","# URL to the raw content of the version file in the repository\n","version_url = \"https://raw.githubusercontent.com/CellMigrationLab/Plot-Stats/main/Notebooks/latest_version.txt\"\n","\n","# Function to define colors for formatting messages\n","class bcolors:\n","    WARNING = '\\033[91m'  # Red color for warning messages\n","    ENDC = '\\033[0m'      # Reset color to default\n","\n","# Check if this is the latest version of the notebook\n","try:\n","    All_notebook_versions = pd.read_csv(version_url, dtype=str)\n","    print('Notebook version: ' + current_version)\n","\n","    # Check if 'Version' column exists in the DataFrame\n","    if 'Version' in All_notebook_versions.columns:\n","        Latest_Notebook_version = All_notebook_versions[All_notebook_versions[\"Notebook\"] == Notebook_name]['Version'].iloc[0]\n","        print('Latest notebook version: ' + Latest_Notebook_version)\n","\n","        if current_version == Latest_Notebook_version:\n","            print(\"This notebook is up-to-date.\")\n","        else:\n","            print(bcolors.WARNING + \"A new version of this notebook has been released. We recommend that you download it at https://github.com/CellMigrationLab/Plot-Stats\" + bcolors.ENDC)\n","    else:\n","        print(\"The 'Version' column is not present in the version file.\")\n","except requests.exceptions.RequestException as e:\n","    print(\"Unable to fetch the latest version information. Please check your internet connection.\")\n","except Exception as e:\n","    print(\"An error occurred:\", str(e))\n","\n","\n","\n","# Function to calculate Cohen's d\n","def cohen_d(group1, group2):\n","    diff = group1.mean() - group2.mean()\n","    n1, n2 = len(group1), len(group2)\n","    var1 = group1.var()\n","    var2 = group2.var()\n","    pooled_var = ((n1 - 1) * var1 + (n2 - 1) * var2) / (n1 + n2 - 2)\n","    d = diff / np.sqrt(pooled_var)\n","    return d\n","\n","def save_dataframe_with_progress(df, path, desc=\"Saving\", chunk_size=50000):\n","    \"\"\"Save a DataFrame with a progress bar.\"\"\"\n","\n","    # Estimating the number of chunks based on the provided chunk size\n","    num_chunks = int(len(df) / chunk_size) + 1\n","\n","    # Create a tqdm instance for progress tracking\n","    with tqdm(total=len(df), unit=\"rows\", desc=desc) as pbar:\n","        # Open the file for writing\n","        with open(path, \"w\") as f:\n","            # Write the header once at the beginning\n","            df.head(0).to_csv(f, index=False)\n","\n","            for chunk in np.array_split(df, num_chunks):\n","                chunk.to_csv(f, mode=\"a\", header=False, index=False)\n","                pbar.update(len(chunk))\n","\n","def check_for_nans(df, df_name):\n","    \"\"\"\n","    Checks the given DataFrame for NaN values and prints the count for each column containing NaNs.\n","\n","    Args:\n","    df (pd.DataFrame): DataFrame to be checked for NaN values.\n","    df_name (str): The name of the DataFrame as a string, used for printing.\n","    \"\"\"\n","    # Check if the DataFrame has any NaN values and print a warning if it does.\n","    nan_columns = df.columns[df.isna().any()].tolist()\n","\n","    if nan_columns:\n","        for col in nan_columns:\n","            nan_count = df[col].isna().sum()\n","            print(f\"Column '{col}' in {df_name} contains {nan_count} NaN values.\")\n","    else:\n","        print(f\"No NaN values found in {df_name}.\")\n","\n","\n","import pandas as pd\n","import os\n","\n","def save_parameters(params, file_path, param_type):\n","    # Convert params dictionary to a DataFrame for human readability\n","    new_params_df = pd.DataFrame(list(params.items()), columns=['Parameter', 'Value'])\n","    new_params_df['Type'] = param_type\n","\n","    if os.path.exists(file_path):\n","        # Read existing file\n","        existing_params_df = pd.read_csv(file_path)\n","\n","        # Merge the new parameters with the existing ones\n","        # Update existing parameters or append new ones\n","        updated_params_df = pd.merge(existing_params_df, new_params_df,\n","                                     on=['Type', 'Parameter'],\n","                                     how='outer',\n","                                     suffixes=('', '_new'))\n","\n","        # If there's a new value, update it, otherwise keep the old value\n","        updated_params_df['Value'] = updated_params_df['Value_new'].combine_first(updated_params_df['Value'])\n","\n","        # Drop the temporary new value column\n","        updated_params_df.drop(columns='Value_new', inplace=True)\n","    else:\n","        # Use new parameters DataFrame directly if file doesn't exist\n","        updated_params_df = new_params_df\n","\n","    # Save the updated DataFrame to CSV\n","    updated_params_df.to_csv(file_path, index=False)\n"]},{"cell_type":"markdown","metadata":{"id":"3Kzd_8GUnpbw"},"source":["## **1.2. Mount your Google Drive**\n","---\n","<font size = 4> To use this notebook on the data present in your Google Drive, you need to mount your Google Drive to this notebook.\n","\n","<font size = 4> Play the cell below to mount your Google Drive and follow the instructions.\n","\n","<font size = 4> Once this is done, your data are available in the **Files** tab on the top left of notebook."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"GA1wCrkoV4i5"},"outputs":[],"source":["#@markdown ##Play the cell to connect your Google Drive to Colab\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","%cd /gdrive\n","\n"]},{"cell_type":"markdown","metadata":{"id":"bsDAwkSOo1gV"},"source":["## **1.3. Load your dataset**\n","---\n","\n","<font size = 4> Please ensure that your data is properly organised (see above)\n"]},{"cell_type":"code","source":["#@markdown ##Load your dataset:\n","\n","import pandas as pd\n","import os\n","from io import StringIO\n","import ipywidgets as widgets\n","from IPython.display import display, clear_output\n","\n","# Initialize dataset_df as an empty DataFrame globally\n","dataset_df = pd.DataFrame()\n","\n","# Create widgets\n","dataset_path_input = widgets.Text(\n","    value='',\n","    placeholder='Enter the path to your dataset',\n","    description='Dataset Path:',\n","    layout={'width': '80%'}\n",")\n","\n","results_folder_input = widgets.Text(\n","    value='',\n","    placeholder='Enter the path to your results folder',\n","    description='Results Folder:',\n","    layout={'width': '80%'}\n",")\n","\n","data_textarea = widgets.Textarea(\n","    value='',\n","    placeholder='Or copy and paste your tab sperated data here (direct copy and paste from a spreedsheet)',\n","    description='Or Paste Data:',\n","    layout={'width': '80%', 'height': '200px'}\n",")\n","\n","load_button = widgets.Button(\n","    description='Load Data',\n","    button_style='success',  # 'success', 'info', 'warning', 'danger' or ''\n","    tooltip='Click to load the data',\n",")\n","\n","output = widgets.Output()\n","\n","# Load data function\n","def load_data(b):\n","    global dataset_df\n","    global Results_Folder\n","\n","    with output:\n","        clear_output()\n","        Results_Folder = results_folder_input.value.strip()\n","        if not Results_Folder:\n","            Results_Folder = './Results'  # Default path if not provided\n","        if not os.path.exists(Results_Folder):\n","            os.makedirs(Results_Folder)  # Create the folder if it doesn't exist\n","        print(f\"Results folder is located at: {Results_Folder}\")\n","\n","        if dataset_path_input.value.strip():\n","            dataset_path = dataset_path_input.value.strip()\n","            try:\n","                dataset_df = pd.read_csv(dataset_path)\n","                print(f\"Loaded dataset from {dataset_path}\")\n","            except Exception as e:\n","                print(f\"Failed to load dataset from {dataset_path}: {e}\")\n","        elif data_textarea.value.strip():\n","            input_data = StringIO(data_textarea.value)\n","            try:\n","                dataset_df = pd.read_csv(input_data, sep='\\t')\n","                print(\"Loaded dataset from pasted tab-separated data\")\n","            except Exception as e:\n","                print(f\"Failed to load dataset from pasted data: {e}\")\n","        else:\n","            print(\"No dataset path provided or data pasted. Please provide a dataset.\")\n","            return\n","\n","        # Perform a check for NaNs or any other required processing here\n","        check_for_nans(dataset_df, \"your dataset\")\n","\n","        display(dataset_df.head())\n","\n","# Set the button click event\n","load_button.on_click(load_data)\n","\n","# Display the widgets\n","display(widgets.VBox([dataset_path_input, results_folder_input, data_textarea, load_button, output]))"],"metadata":{"cellView":"form","id":"yIX1uUc3NpCS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown ##Transform your dataset to tidy format:\n","\n","\n","import pandas as pd\n","import numpy as np\n","\n","df_wide = dataset_df\n","\n","# Add an artificial index column if no natural unique identifier exists\n","df_wide['Index'] = range(1, len(df_wide) + 1)\n","\n","# Melt the DataFrame to long format\n","df_long = pd.melt(df_wide, id_vars=['Index'], var_name='Condition_Repeat', value_name='Measurement')\n","\n","# Drop NaN values to handle varying data points across columns\n","df_long = df_long.dropna(subset=['Measurement'])\n","\n","# Optionally, split 'Condition_Repeat' into separate 'Condition' and 'Repeat' columns\n","df_long[['Condition', 'Repeat']] = df_long['Condition_Repeat'].str.rsplit('_R', n=1, expand=True)\n","\n","# Drop the artificial 'Index' column if it's no longer needed, or keep it if it helps in further analysis\n","df_long = df_long.drop(columns=['Index'])\n","\n","print(df_long)\n","\n","\n","def validate_mappings(df_long):\n","    condition_repeat_sets = df_long.groupby('Condition')['Repeat'].apply(set)\n","\n","    # Check if all conditions have the same set of repeats\n","    first_set = next(iter(condition_repeat_sets), set())\n","    if all(repeat_set == first_set for repeat_set in condition_repeat_sets):\n","        print(\"Validation Passed: All conditions have the same set of repeats.\")\n","    else:\n","        print(\"Warning: Not all conditions have the same set of repeats. Please check your data.\")\n","\n","# Call the validation function\n","validate_mappings(df_long)\n","\n","display(df_long.head())\n","\n","# Save the tidy dataset to a CSV file\n","df_long.to_csv(Results_Folder+'/tidy_dataset.csv', index=False)\n","\n"],"metadata":{"cellView":"form","id":"0W0scjsLrYHY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cd817UHYhCGD"},"source":["# **Part 2. Version log**\n","---\n","<font size = 4>While I strive to provide accurate and helpful information, please be aware that:\n","  - This notebook may contain bugs.\n","  - Features are currently limited and will be expanded in future releases.\n","\n","<font size = 4>We encourage users to report any issues or suggestions for improvement. Please check the [repository](https://github.com/guijacquemet/CellTracksColab) regularly for updates and the latest version of this notebook.\n","\n","\n","<font size = 4>**Version 0.1**\n","This is the first release of this notebook.\n","\n","---"]}],"metadata":{"colab":{"provenance":[{"file_id":"1fFblyBiEW50U7prm2dTtiIiJFWI-Q8v-","timestamp":1709225779782}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}